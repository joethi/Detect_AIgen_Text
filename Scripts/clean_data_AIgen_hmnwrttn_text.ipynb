{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End To End Azure NLP Project: Detect AI Generated Text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Azure_end_to_end_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# from huggingface_hub import list_datasets\n",
    "# print(len([dataset.id for dataset in list_datasets()]))\n",
    "\n",
    "LLM_gen_dataset = load_dataset(\"perlthoughts/big-brain-4k\")\n",
    "LLM_train_set = LLM_gen_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_gen_dataset = load_dataset(\"qwedsacf/ivypanda-essays\")\n",
    "human_gen_dataset_train = human_gen_dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Data Into Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human = pd.DataFrame(human_gen_dataset_train)\n",
    "df_AI = pd.DataFrame(LLM_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping The Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human_pcs = df_human.drop(['SOURCE','__index_level_0__'],axis=1)\n",
    "df_AI_pcs = df_AI.drop(['system','prompt'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing The Empty Strings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rplc_emptystr_w_nan(df_data_pcs):\n",
    "    df_trns_nan = df_data_pcs.map(lambda x: np.nan if isinstance(x, str) and x.strip() == '' else x)\n",
    "    # Create a boolean Series where each value indicates if any value in the row is NaN\n",
    "    bool_series = df_trns_nan.isna().any(axis=1)\n",
    "    # Use the boolean Series to index the DataFrame\n",
    "    rows_with_nan = df_trns_nan[bool_series] \n",
    "    return rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TEXT]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rplc_emptystr_w_nan(df_human_pcs)\n",
    "#No empty strings in human pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1  Column2  Column3\n",
      "0      1.0      NaN      1.0\n",
      "1      2.0      2.0      0.2\n",
      "2      NaN      3.0      3.0\n",
      "3      4.0      4.0      4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3\n",
       "0      1.0      NaN      1.0\n",
       "2      NaN      3.0      3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Column1': [1, 2, np.nan, 4],\n",
    "        'Column2': [np.nan, 2, 3, 4],\n",
    "        'Column3': [1, 0.2, 3, 4]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head()) \n",
    "rplc_emptystr_w_nan(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The review is neutral. The reviewer did not ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, let's solve this math problem together! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As an AI, I understand you are asking for a tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sentence is acceptable. It means that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The article does not provide the last name of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>First, we find the prime factorization of each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>The prime numbers in the list are 23 and 29.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>The students are advised to eat normal-sized m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>Jean thought \"David\" was special because he ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>homology.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   output\n",
       "0       The review is neutral. The reviewer did not ha...\n",
       "1       Okay, let's solve this math problem together! ...\n",
       "2       As an AI, I understand you are asking for a tw...\n",
       "3       The sentence is acceptable. It means that the ...\n",
       "4       The article does not provide the last name of ...\n",
       "...                                                   ...\n",
       "249995  First, we find the prime factorization of each...\n",
       "249996  The prime numbers in the list are 23 and 29.\\n...\n",
       "249997  The students are advised to eat normal-sized m...\n",
       "249998  Jean thought \"David\" was special because he ma...\n",
       "249999                                          homology.\n",
       "\n",
       "[250000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are an AI assistant. Provide a detailed an...</td>\n",
       "      <td>Title: I did not get to see it because I could...</td>\n",
       "      <td>The review is neutral. The reviewer did not ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful assistant, who always provid...</td>\n",
       "      <td>Solve this math problem\\n\\nSolve -20*l + 41*l ...</td>\n",
       "      <td>Okay, let's solve this math problem together! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are an AI assistant. You will be given a t...</td>\n",
       "      <td>Sentiment possibilities Possible answers: 1). ...</td>\n",
       "      <td>As an AI, I understand you are asking for a tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful assistant, who always provid...</td>\n",
       "      <td>Multi-choice problem: Is the next sentence syn...</td>\n",
       "      <td>The sentence is acceptable. It means that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are an AI assistant that follows instructi...</td>\n",
       "      <td>I have a test where I am given the following a...</td>\n",
       "      <td>The article does not provide the last name of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              system  \\\n",
       "0  You are an AI assistant. Provide a detailed an...   \n",
       "1  You are a helpful assistant, who always provid...   \n",
       "2  You are an AI assistant. You will be given a t...   \n",
       "3  You are a helpful assistant, who always provid...   \n",
       "4  You are an AI assistant that follows instructi...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Title: I did not get to see it because I could...   \n",
       "1  Solve this math problem\\n\\nSolve -20*l + 41*l ...   \n",
       "2  Sentiment possibilities Possible answers: 1). ...   \n",
       "3  Multi-choice problem: Is the next sentence syn...   \n",
       "4  I have a test where I am given the following a...   \n",
       "\n",
       "                                              output  \n",
       "0  The review is neutral. The reviewer did not ha...  \n",
       "1  Okay, let's solve this math problem together! ...  \n",
       "2  As an AI, I understand you are asking for a tw...  \n",
       "3  The sentence is acceptable. It means that the ...  \n",
       "4  The article does not provide the last name of ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following article contains an answer for the question: Who steals supplies from other trucks? , can you please find it?   Cooper and Durazno knock out a truck driver and steal his rig. They take it back to a shop where it is repainted and the numbers are filed. In it they find a truckload of carburetors. Cooper abandons Durazno at a gas station and sets out as an independent driver of the yellow Peterbilt. He picks up a hitchhiker but refuses to also give a ride to the man's accompanying woman and dog. At a diner the two notice the Duke of Interstate 40 (Hector Elizondo) eating at another table. Cooper asks him about his rig, which annoys the Duke. Cooper and the hitchhiker watch Samson and Delilah at a drive-in as Cooper discusses professions he's considered as a means to make money and how he reads the almanac so that he can be learning and earning money at the same time. Cooper visits a shopkeeper and attempts to earn money by either selling some of the stolen carburetors or hustling work as an independent hauler but is turned down because the shopkeeper works with the wholesalers. The hitchhiker finds several prospective customers in the meantime and they pack the already-full truck with tiles and live chickens to be hauled, stealing food and supplies from other trucks. They visit the place where Cooper says his wife lives but she is not there. They are pulled over by a policeman and Cooper lies that he recently returned from the war to get the officer to let him go quickly without checking the contents of the truck. During the night Cooper takes Benzedrine to stay awake while driving.\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(df_AI[\"prompt\"][15637])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31616</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33376</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51534</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57974</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87873</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107100</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108134</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123018</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138969</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147350</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147355</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151838</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152416</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158193</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173788</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181795</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181988</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184754</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190111</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221023</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225525</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237527</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249000</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "4408      NaN\n",
       "15637     NaN\n",
       "31616     NaN\n",
       "33376     NaN\n",
       "51534     NaN\n",
       "57974     NaN\n",
       "87873     NaN\n",
       "107100    NaN\n",
       "108134    NaN\n",
       "123018    NaN\n",
       "138969    NaN\n",
       "147350    NaN\n",
       "147355    NaN\n",
       "151838    NaN\n",
       "152416    NaN\n",
       "158193    NaN\n",
       "173788    NaN\n",
       "181795    NaN\n",
       "181988    NaN\n",
       "184754    NaN\n",
       "190111    NaN\n",
       "221023    NaN\n",
       "225525    NaN\n",
       "237527    NaN\n",
       "249000    NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rplc_emptystr_w_nan(df_AI_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rplc_emptystr_w_nan_v2(df_data_pcs):\n",
    "    df_trns_nan = df_data_pcs.map(lambda x: np.nan if isinstance(x, str) and x.strip() == '' else x)\n",
    "    # Create a boolean Series where each value indicates if any value in the row is NaN\n",
    "    bool_series = df_trns_nan.isna().any(axis=1)\n",
    "    # Use the boolean Series to index the DataFrame\n",
    "    rows_with_nan = df_trns_nan[bool_series]\n",
    "     \n",
    "    return df_trns_nan, rows_with_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_wnan, df_rows_nan = rplc_emptystr_w_nan_v2(df_AI_pcs)\n",
    "df_AI_pcs = df_AI_wnan.dropna().reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The review is neutral. The reviewer did not ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay, let's solve this math problem together! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As an AI, I understand you are asking for a tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sentence is acceptable. It means that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The article does not provide the last name of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249970</th>\n",
       "      <td>First, we find the prime factorization of each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249971</th>\n",
       "      <td>The prime numbers in the list are 23 and 29.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249972</th>\n",
       "      <td>The students are advised to eat normal-sized m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249973</th>\n",
       "      <td>Jean thought \"David\" was special because he ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249974</th>\n",
       "      <td>homology.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249975 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   output\n",
       "0       The review is neutral. The reviewer did not ha...\n",
       "1       Okay, let's solve this math problem together! ...\n",
       "2       As an AI, I understand you are asking for a tw...\n",
       "3       The sentence is acceptable. It means that the ...\n",
       "4       The article does not provide the last name of ...\n",
       "...                                                   ...\n",
       "249970  First, we find the prime factorization of each...\n",
       "249971  The prime numbers in the list are 23 and 29.\\n...\n",
       "249972  The students are advised to eat normal-sized m...\n",
       "249973  Jean thought \"David\" was special because he ma...\n",
       "249974                                          homology.\n",
       "\n",
       "[249975 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>The review is positive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249900</th>\n",
       "      <td>Educational institution.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249902</th>\n",
       "      <td>The writer's purpose of writing the passage is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249929</th>\n",
       "      <td>An example of a tweet is: \"Just finished a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249944</th>\n",
       "      <td>Yes, this product review is negative.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249971</th>\n",
       "      <td>The prime numbers in the list are 23 and 29.\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16803 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   output\n",
       "214                                                    No\n",
       "313                                                    No\n",
       "450                               The review is positive.\n",
       "542                                                   No.\n",
       "587                                                    No\n",
       "...                                                   ...\n",
       "249900                           Educational institution.\n",
       "249902  The writer's purpose of writing the passage is...\n",
       "249929  An example of a tweet is: \"Just finished a gre...\n",
       "249944              Yes, this product review is negative.\n",
       "249971  The prime numbers in the list are 23 and 29.\\n...\n",
       "\n",
       "[16803 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_pcs[df_AI_pcs.duplicated()]\n",
    "# df_AI_pcs[\"output\"][249929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the indices after removing the duplicates.\n",
    "df_AI_pcs = df_AI_pcs.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TEXT]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_pcs[df_human_pcs.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Check out this link: https://www.example.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No URL here!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Another link: http://example.org</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This text contains a URL: www.test.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  has_url\n",
       "0  Check out this link: https://www.example.com     True\n",
       "1                                  No URL here!    False\n",
       "2              Another link: http://example.org     True\n",
       "3        This text contains a URL: www.test.com     True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the text data has URL: Source: ChatGPT\n",
    "import re\n",
    "def contains_url(text: str) -> bool:\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return bool(url_pattern.search(text))\n",
    "\n",
    "data = {\n",
    "    'text': [\n",
    "        \"Check out this link: https://www.example.com\",\n",
    "        \"No URL here!\",\n",
    "        \"Another link: http://example.org\",\n",
    "        \"This text contains a URL: www.test.com\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['has_url'] = df['text'].apply(contains_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_dummy = pd.DataFrame()\n",
    "df_AI_dummy[\"has_url\"] = df_AI_pcs[\"output\"].apply(lambda x: contains_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230728</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230778</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231572</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232245</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232987</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_url\n",
       "184        True\n",
       "350        True\n",
       "467        True\n",
       "1278       True\n",
       "1376       True\n",
       "...         ...\n",
       "230728     True\n",
       "230778     True\n",
       "231572     True\n",
       "232245     True\n",
       "232987     True\n",
       "\n",
       "[721 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_dummy[df_AI_dummy[\"has_url\"]==True]\n",
    "#ok there are URLS in AI text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I can't provide a complete list of all tutorials available for LISP programming, but I can help get you started with some essential resources and a brief overview of the language.\n",
      "\n",
      "LISP (short for List Processing) is one of the oldest high-level programming languages, primarily used for artificial intelligence (AI) and symbolic computing. The language is characterized by its parenthetical syntax and support for powerful data manipulation using lists.\n",
      "\n",
      "Here are some resources to help you learn LISP:\n",
      "\n",
      "1. **Official documentation**: The \"Common Lisp Hyperspec\" is a comprehensive online reference to the Common Lisp language. Start here for definitive information on language features, syntax, and standard library: http://www.lispworks.com/documentation/HyperSpec/Front/index.htm\n",
      "\n",
      "2. **Books**:\n",
      "   - \"Practical Common Lisp\" by Peter Seibel: This book is suitable for beginners and provides practical examples of LISP programming. The full text is available online: http://www.gigamonkeys.com/book/\n",
      "   - \"Common Lisp: A Gentle Introduction to Symbolic Computation\" by David S. Touretzky: This book is designed for readers with no programming experience, and provides an introduction to LISP. The full text is available online: https://www.cs.cmu.edu/~dst/LispBook/index.html\n",
      "\n",
      "3. **Online tutorials and courses**:\n",
      "   - \"LISPy: A Gentle Introduction to Emacs Lisp in 300 Lines\" by Tom Stuart: An interactive tutorial that teaches you Emacs Lisp by building a small game. https://www.youtube.com/watch?v=5FFO-_fzews\n",
      "   - \"LispCast: Introduction to Lisp\": This screencast series covers the basics of Lisp, with a focus on practical applications for everyday programmers. https://lispcast.com/introduction-to-lisp/\n",
      "   - Coursera's \"Functional Programming Principles in Scala\": Though not centered on Lisp, this course teaches functional programming concepts applicable to Lisp programming. https://www.coursera.org/learn/progfun1\n",
      "\n",
      "4. **Development environments and resources**:\n",
      "   - SBCL (Steel Bank Common Lisp): A high-performance Common Lisp compiler, ideal for getting started. http://www.sbcl.org/\n",
      "   - Emacs and SLIME: Emacs is a powerful text editor, and SLIME is an Emacs mode for interacting with Common Lisp environments. These resources provide a powerful LISP development environment. https://www.gnu.org/software/emacs/ and https://common-lisp.net/project/slime/\n",
      "\n",
      "These are just a few resources to get you started with LISP programming. When learning a new language, it can be helpful to work through tutorials, read books, and practice solving problems on your own. Good luck!\n"
     ]
    }
   ],
   "source": [
    "print(df_AI_pcs[\"output\"][184])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New competition launched :'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "example=\"New competition launched :https://www.kaggle.com/c/nlp-getting-started\"\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "remove_URL(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   output\n",
      "0       The review is neutral. The reviewer did not ha...\n",
      "1       Okay, let's solve this math problem together! ...\n",
      "2       As an AI, I understand you are asking for a tw...\n",
      "3       The sentence is acceptable. It means that the ...\n",
      "4       The article does not provide the last name of ...\n",
      "...                                                   ...\n",
      "233167  We can convert $\\frac{5}{14}$ into a decimal b...\n",
      "233168  First, we find the prime factorization of each...\n",
      "233169  The students are advised to eat normal-sized m...\n",
      "233170  Jean thought \"David\" was special because he ma...\n",
      "233171                                          homology.\n",
      "\n",
      "[233172 rows x 1 columns]\n",
      "As an AI language model, I can't provide a complete list of all tutorials available for LISP programming, but I can help get you started with some essential resources and a brief overview of the language.\n",
      "\n",
      "LISP (short for List Processing) is one of the oldest high-level programming languages, primarily used for artificial intelligence (AI) and symbolic computing. The language is characterized by its parenthetical syntax and support for powerful data manipulation using lists.\n",
      "\n",
      "Here are some resources to help you learn LISP:\n",
      "\n",
      "1. **Official documentation**: The \"Common Lisp Hyperspec\" is a comprehensive online reference to the Common Lisp language. Start here for definitive information on language features, syntax, and standard library: \n",
      "\n",
      "2. **Books**:\n",
      "   - \"Practical Common Lisp\" by Peter Seibel: This book is suitable for beginners and provides practical examples of LISP programming. The full text is available online: \n",
      "   - \"Common Lisp: A Gentle Introduction to Symbolic Computation\" by David S. Touretzky: This book is designed for readers with no programming experience, and provides an introduction to LISP. The full text is available online: \n",
      "\n",
      "3. **Online tutorials and courses**:\n",
      "   - \"LISPy: A Gentle Introduction to Emacs Lisp in 300 Lines\" by Tom Stuart: An interactive tutorial that teaches you Emacs Lisp by building a small game. \n",
      "   - \"LispCast: Introduction to Lisp\": This screencast series covers the basics of Lisp, with a focus on practical applications for everyday programmers. \n",
      "   - Coursera's \"Functional Programming Principles in Scala\": Though not centered on Lisp, this course teaches functional programming concepts applicable to Lisp programming. \n",
      "\n",
      "4. **Development environments and resources**:\n",
      "   - SBCL (Steel Bank Common Lisp): A high-performance Common Lisp compiler, ideal for getting started. \n",
      "   - Emacs and SLIME: Emacs is a powerful text editor, and SLIME is an Emacs mode for interacting with Common Lisp environments. These resources provide a powerful LISP development environment.  and \n",
      "\n",
      "These are just a few resources to get you started with LISP programming. When learning a new language, it can be helpful to work through tutorials, read books, and practice solving problems on your own. Good luck!\n"
     ]
    }
   ],
   "source": [
    "df_AI_pcs[\"output\"] = df_AI_pcs[\"output\"].apply(lambda x : remove_URL(x))\n",
    "print(df_AI_pcs)\n",
    "print(df_AI_pcs[\"output\"][184])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128235</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128236</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128239</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128279</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128281</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5246 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_url\n",
       "31         True\n",
       "291        True\n",
       "341        True\n",
       "737        True\n",
       "1460       True\n",
       "...         ...\n",
       "128235     True\n",
       "128236     True\n",
       "128239     True\n",
       "128279     True\n",
       "128281     True\n",
       "\n",
       "[5246 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_dummy = pd.DataFrame()\n",
    "df_human_dummy[\"has_url\"] = df_human_pcs[\"TEXT\"].apply(lambda x: contains_url(x))\n",
    "df_human_dummy[df_human_dummy[\"has_url\"] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting Basics and How to Remember Them Essay\n",
      "\n",
      "The rhythmic accounting rap song Debit Credit Theory by Colin Dodds (n.d.) is an excellent way to remember that debit’s location is the left side of the account, and credit’s location is the right one. This unusual song also explains the meaning of these two terms. This fun but an educational source has enabled me to remember the material and not get confused in the concepts.\n",
      "\n",
      "A link: https://www.youtube.com/watch?v=j71Kmxv7smk\n",
      "\n",
      "The mnemonic offered by Heather McNellis (2020) also contributes to better understanding and remembering the essence of debit and credit and the account balances. The DEAL/CLIP mnemonic contains the explanation of debit’s and credit’s parts. Due to this engaging technic, it is pretty easy to understand that while debit includes Drawings, Expenses, Assets, and Losses, credit consists of Capital, Liabilities, Income, as well as Profits.\n",
      "\n",
      "A link: https://www.icas.com/students/learning-blog/test-of-competence/financial-accounting-whats-the-dealclip-with-debits-and-credits\n",
      "\n",
      "I have chosen these two sources since they make it easy to remember accounting basics. They are pretty bright, fun, and engaging: due to the song chorus, it is impossible to forget where debit and credit are located, and mnemonics help remember all their constituents. I think other students will also like them since they are suitable for people with different types of information perception.\n",
      "\n",
      "How Would You Define Ethics?\n",
      "\n",
      "Ethics is a set of norms of behavior adopted in society or any social group.\n",
      "\n",
      "What are Three Factors that Might Affect Good Ethical Conduct?\n",
      "\n",
      "The factors influencing ethical conduct are divided into three levels: individual, involving the personal values, social, or organizational, including norms of the organization, and opportunity ones that are situations requiring ethical or unethical decisions.\n",
      "\n",
      "An Explanation of Why the Sarbanes-Oxley Act Was Created\n",
      "\n",
      "The Sarbanes-Oxley Act was created to make it impossible for managers and accountants to misuse funds. It resulted from high-profile scandals with corporate reporting, due to which investors began to doubt the reliability of the data provided by companies. This Act also relates to ethics since it contains the set of norms and principles of fair leading a business.\n",
      "\n",
      "What Are the Legal Liabilities of an Accountant?\n",
      "\n",
      "The accountant is responsible for maintaining all financial calculations of the company, as well as the reliability of data, and they are liable for misstatements and mistakes made by them. However, the Generally Accepted Accounting Principles claim the employee is not responsible for misstatements if they work in good faith.\n",
      "\n",
      "References\n",
      "\n",
      "McNellis, H. (2020). Financial accounting: What’s the DEAL/CLIP with debits and credits? ICAS. Web.\n",
      "\n",
      "Mr. Colin Dodds. (n.d.). Debit credit theory: Accounting rap song [Video]. YouTube. Web.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_human_pcs[\"TEXT\"][31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting Basics and How to Remember Them Essay\n",
      "\n",
      "The rhythmic accounting rap song Debit Credit Theory by Colin Dodds (n.d.) is an excellent way to remember that debit’s location is the left side of the account, and credit’s location is the right one. This unusual song also explains the meaning of these two terms. This fun but an educational source has enabled me to remember the material and not get confused in the concepts.\n",
      "\n",
      "A link: \n",
      "\n",
      "The mnemonic offered by Heather McNellis (2020) also contributes to better understanding and remembering the essence of debit and credit and the account balances. The DEAL/CLIP mnemonic contains the explanation of debit’s and credit’s parts. Due to this engaging technic, it is pretty easy to understand that while debit includes Drawings, Expenses, Assets, and Losses, credit consists of Capital, Liabilities, Income, as well as Profits.\n",
      "\n",
      "A link: \n",
      "\n",
      "I have chosen these two sources since they make it easy to remember accounting basics. They are pretty bright, fun, and engaging: due to the song chorus, it is impossible to forget where debit and credit are located, and mnemonics help remember all their constituents. I think other students will also like them since they are suitable for people with different types of information perception.\n",
      "\n",
      "How Would You Define Ethics?\n",
      "\n",
      "Ethics is a set of norms of behavior adopted in society or any social group.\n",
      "\n",
      "What are Three Factors that Might Affect Good Ethical Conduct?\n",
      "\n",
      "The factors influencing ethical conduct are divided into three levels: individual, involving the personal values, social, or organizational, including norms of the organization, and opportunity ones that are situations requiring ethical or unethical decisions.\n",
      "\n",
      "An Explanation of Why the Sarbanes-Oxley Act Was Created\n",
      "\n",
      "The Sarbanes-Oxley Act was created to make it impossible for managers and accountants to misuse funds. It resulted from high-profile scandals with corporate reporting, due to which investors began to doubt the reliability of the data provided by companies. This Act also relates to ethics since it contains the set of norms and principles of fair leading a business.\n",
      "\n",
      "What Are the Legal Liabilities of an Accountant?\n",
      "\n",
      "The accountant is responsible for maintaining all financial calculations of the company, as well as the reliability of data, and they are liable for misstatements and mistakes made by them. However, the Generally Accepted Accounting Principles claim the employee is not responsible for misstatements if they work in good faith.\n",
      "\n",
      "References\n",
      "\n",
      "McNellis, H. (2020). Financial accounting: What’s the DEAL/CLIP with debits and credits? ICAS. Web.\n",
      "\n",
      "Mr. Colin Dodds. (n.d.). Debit credit theory: Accounting rap song [Video]. YouTube. Web.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_human_pcs[\"TEXT\"] = df_human_pcs[\"TEXT\"].apply(lambda x : remove_URL(x))\n",
    "print(df_human_pcs[\"TEXT\"][31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Omg another Earthquake '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "remove_emoji(\"Omg another Earthquake 😔😔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_pcs[\"output\"] = df_AI_pcs[\"output\"].apply(lambda x : remove_emoji(x))\n",
    "df_human_pcs[\"TEXT\"] = df_human_pcs[\"TEXT\"].apply(lambda x : remove_emoji(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and remove the HTML tags:\n",
    "def contains_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return bool(html.search(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127927</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127934</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127936</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127937</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127961</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_html\n",
       "373         True\n",
       "709         True\n",
       "1478        True\n",
       "1630        True\n",
       "1693        True\n",
       "...          ...\n",
       "127927      True\n",
       "127934      True\n",
       "127936      True\n",
       "127937      True\n",
       "127961      True\n",
       "\n",
       "[1663 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_dummy = pd.DataFrame()\n",
    "df_human_dummy[\"has_html\"] = df_human_pcs[\"TEXT\"].apply(lambda x: contains_html(x))\n",
    "df_human_dummy[df_human_dummy[\"has_html\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop Platform: Usage and Significance Research Paper\n",
      "\n",
      "Hadoop and its Operations\n",
      "\n",
      "Hadoop is an open-source platform commonly used for the storage and processing of big data. It is an approach that enhances the efficiency scale in analyzing massive datasets across different connected computers. Although a single computer can process big data based on schematics, networking improves productivity in processing information from dynamic sectors. Hadoop is a technological tool essential in the modern world due to the increasing gathering and processing of big data (Data Flair, 2022). Different institutions use the dataset for dynamic purposes, such as analyzing the behavioral indicator during the purchasing process. Therefore, it is the responsibility of executive teams to establish critical frameworks that enhance the derivation of in-depth details concerning the distinctive variables. The lack of clarity fosters subjective decision-making that results in bias due to inadequate knowledge of vital topical issues.\n",
      "\n",
      "Significance of Big Data Management\n",
      "\n",
      "Different organizations participate in the extensive data analysis due to the outcome concerning the derived apt insights on emerging trends in an industry. Over the decades, a significant percentage of the population incorporated systems across distinct sectors, such as healthcare and law-and-order practices. In this case, it is easier for a person to use big data to analyze a particular conceptual framework. Therefore, dataset management plays a crucial role in advocating for understanding consumer behavior and pattern. In a different spectrum, the processing of the quotient is an empowerment tool for artificial intelligence systems (Rowe, 2016). As a result, it is the responsibility of distinct stakeholders to exploit the massive dataset to enhance companies’ competitive advantage in marketing. Primarily, corporates invest in data analytics to attain vital information regarding their clients and the evolutionary trends. Notably, the executive team develops marketing strategies and product diversification features based on the preferential baseline.\n",
      "\n",
      "Hadoop’s Big Data Management Security\n",
      "\n",
      "Hadoop technology is a secure way to manage data due to the significant intersection of adept coding and storage structures. It is essential to distribute the big data processing across different computer mainframes to reduce the risk of overloading one computer. In this case, networking also fosters gathering specific information from various sectors and processing crucial details (Data Flair, 2022). An excellent example is the utilization of the framework in a healthcare institution. On the one hand, massive dataset processing in a clinic fosters the derivation of statistics based on clientele recovery and re-hospitalization rate. On the other hand, medical practitioners invest resources on common issues causing the prevalence of certain conditions. One of the insights that rely on extensive dataset management is understanding the dynamic lifestyle habits and implications to personal well-being. The exploitation of the dataset fosters an overview regarding the causative agents to physicians’ demand for more health-based details. Primarily, it is safe to use Hadoop to manage big data since it enlightens the stakeholders concerning specific issues within a single spectrum, such as healthcare quality.\n",
      "\n",
      "Hadoop as A Recommended Big Data Analytics Technology\n",
      "\n",
      "I would recommend using Hadoop to manage big data due to the importance of enhancing productivity. Efficiency in utilizing massive datasets empowers corporates with insights regarding distinctive approaches to consumer behavioral patterns. Apart from the necessity of understanding the clientele, other institutions sufficiently comprehend the changes in a particular system. An excellent example is the gathering weather changes and sequence as a formative strategy to demonstrate the unprecedented climate change. In this case, it is key stakeholders’ responsibility to uphold the relevance of Hadoop due to the intersection of dynamic details. Hadoop technology significantly contributes to the execution and implementation of action plans objectively (Data Flair, 2022). Over the decades, the intensification in technological use rendered the increase in the scoop of big data daily. As a result, data analytics corporates seek approaches, such as using Hadoop to enhance the productivity scale on adjusting to the evolutionary cycle. Therefore, Hadoop is recommended to boost the performance rationale across different professional practices and sectors.\n",
      "\n",
      "Hadoop Code and The Significance\n",
      "\n",
      "There are different coding mechanisms within the Hadoop system for optimal outcomes. The two standard codes include mapper and reducer, which mainly enhance datasets’ compilation under the spectrum of divide and conquer. Therefore, programmers exploit the coded language to analyze distinctive massive datasets for specific information. Below is a description of the mapper and reducer codes and their significance to the processing.\n",
      "\n",
      "Mapper code\n",
      "\n",
      "1  publicstaticclassMap extendsMapper<LongWritable,Text,Text,IntWritable>{                              \n",
      "2  publicvoidmap(LongWritable key, Text value, Context context) throwsIOException,InterruptedException {\n",
      "3  String line = value.toString();                                                                      \n",
      "4  StringTokenizer tokenizer = newStringTokenizer(line);                                                \n",
      "5  while(tokenizer.hasMoreTokens()) {                                                                   \n",
      "6  value.set(tokenizer.nextToken());                                                                    \n",
      "7  context.write(value, newIntWritable(1));                                                             \n",
      "8  }                                                                                                    \n",
      "\n",
      "\n",
      "The code represents the class-map used to extend the mapper defined in the MapReduce framework. In this case, the program significantly utilizes the coding to establish inherent values on input and output keys after the declaration by using the angle brackets. In this case, a java code is used in tokenizing every word and assigning a hardcoded key equivalent to 1.\n",
      "\n",
      "Reducer Code\n",
      "\n",
      "1   publicstaticclassReduce extendsReducer<Text,IntWritable,Text,IntWritable>{\n",
      "2   publicvoidreduce(Text key, Iterablevalues,Context context)                \n",
      "3   throwsIOException,InterruptedException {                                  \n",
      "4   intsum=0;                                                                 \n",
      "5   for(IntWritable x: values)                                                \n",
      "6   {                                                                         \n",
      "7   sum+=x.get();                                                             \n",
      "8   }                                                                         \n",
      "9   context.write(key, newIntWritable(sum));                                  \n",
      "10  }                                                                         \n",
      "11  }                                                                         \n",
      "\n",
      "\n",
      "The above is a reducer class code that enshrines the apt use of extension in the ClassReducer. The input and output keys significantly attributed to the key-value pair and the necessity of boosting the performance scale. It is vital to establish the distinctive role of a single reducer using unique words to get a final answer. The Hadoop coding operates under the divide and rule perspective. In this case, the programmer focuses on the intersection of mapper and reducer to enhance the analysis of a weather update and the prediction of changes in the future. Therefore, the coded approach is an essential attributable baseline for corporates in improving the optimal gathering and analysis of big data.\n",
      "\n",
      "Hadoop Interface Tools and Their Roles\n",
      "\n",
      "The two primary Hadoop tools encompass HDFS and YARN, which play a crucial role in the performance scale of the system. HDFS focuses on the storage of big data and the ease of accessibility. In this case, Hadoop ensures the apt function of the storage units for the information gathered and prepared for assessment. YARN is another tool used for processing the collected big data (Data Flair, 2022). The element utilizes different codes in the management and analyses of the dataset to derive crucial insights. The lack of clarity risks miscommunication and inefficient execution of action plans. Therefore, it is the responsibility of programmers to establish core values on intersecting the YARN and HDFS values for adept productivity across the various institutions. The coordination of storage and processing units fosters intensifying the derivation of crucial details. As a result, it is essential to ensure optimal professionalism in the coding structure.\n",
      "\n",
      "The List of Companies using Hadoop Technology\n",
      "\n",
      "  * Marks and Spencer\n",
      "  * Royal Mail\n",
      "  * British Airways\n",
      "  * Royal Bank of Scotland\n",
      "  * Expedia\n",
      "  * Amazon Web Services\n",
      "  * ScienceSoft\n",
      "  * Pivotal\n",
      "  * IBM\n",
      "  * Microsoft\n",
      "  * Hortonworks\n",
      "  * MapR\n",
      "  * Datameer\n",
      "  * Adello\n",
      "  * Hadapt\n",
      "  * Kamasphere\n",
      "  * NG Data\n",
      "\n",
      "References\n",
      "\n",
      "Data Flair. (2022). 12 frequently used Hadoop HDFS Commands with Examples & usage. Web.\n",
      "\n",
      "Rowe, W. (2016). Hadoop Tutorial for Beginners: Hadoop Basics. [online] BMC Blogs. Web.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_human_pcs[\"TEXT\"][373])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232342</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232910</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233030</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233107</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233134</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1698 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_html\n",
       "23          True\n",
       "86          True\n",
       "427         True\n",
       "457         True\n",
       "744         True\n",
       "...          ...\n",
       "232342      True\n",
       "232910      True\n",
       "233030      True\n",
       "233107      True\n",
       "233134      True\n",
       "\n",
       "[1698 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_dummy = pd.DataFrame()\n",
    "df_AI_dummy[\"has_html\"] = df_AI_pcs[\"output\"].apply(lambda x: contains_html(x))\n",
    "df_AI_dummy[df_AI_dummy[\"has_html\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real or Fake\n",
      "Kaggle \n",
      "getting started\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = \"\"\"<div>\n",
    "<h1>Real or Fake</h1>\n",
    "<p>Kaggle </p>\n",
    "<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n",
    "</div>\"\"\"\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "print(remove_html(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_pcs[\"output\"] = df_AI_pcs[\"output\"].apply(lambda x : remove_html(x))\n",
    "df_human_pcs[\"TEXT\"] = df_human_pcs[\"TEXT\"].apply(lambda x : remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop Platform: Usage and Significance Research Paper\n",
      "\n",
      "Hadoop and its Operations\n",
      "\n",
      "Hadoop is an open-source platform commonly used for the storage and processing of big data. It is an approach that enhances the efficiency scale in analyzing massive datasets across different connected computers. Although a single computer can process big data based on schematics, networking improves productivity in processing information from dynamic sectors. Hadoop is a technological tool essential in the modern world due to the increasing gathering and processing of big data (Data Flair, 2022). Different institutions use the dataset for dynamic purposes, such as analyzing the behavioral indicator during the purchasing process. Therefore, it is the responsibility of executive teams to establish critical frameworks that enhance the derivation of in-depth details concerning the distinctive variables. The lack of clarity fosters subjective decision-making that results in bias due to inadequate knowledge of vital topical issues.\n",
      "\n",
      "Significance of Big Data Management\n",
      "\n",
      "Different organizations participate in the extensive data analysis due to the outcome concerning the derived apt insights on emerging trends in an industry. Over the decades, a significant percentage of the population incorporated systems across distinct sectors, such as healthcare and law-and-order practices. In this case, it is easier for a person to use big data to analyze a particular conceptual framework. Therefore, dataset management plays a crucial role in advocating for understanding consumer behavior and pattern. In a different spectrum, the processing of the quotient is an empowerment tool for artificial intelligence systems (Rowe, 2016). As a result, it is the responsibility of distinct stakeholders to exploit the massive dataset to enhance companies’ competitive advantage in marketing. Primarily, corporates invest in data analytics to attain vital information regarding their clients and the evolutionary trends. Notably, the executive team develops marketing strategies and product diversification features based on the preferential baseline.\n",
      "\n",
      "Hadoop’s Big Data Management Security\n",
      "\n",
      "Hadoop technology is a secure way to manage data due to the significant intersection of adept coding and storage structures. It is essential to distribute the big data processing across different computer mainframes to reduce the risk of overloading one computer. In this case, networking also fosters gathering specific information from various sectors and processing crucial details (Data Flair, 2022). An excellent example is the utilization of the framework in a healthcare institution. On the one hand, massive dataset processing in a clinic fosters the derivation of statistics based on clientele recovery and re-hospitalization rate. On the other hand, medical practitioners invest resources on common issues causing the prevalence of certain conditions. One of the insights that rely on extensive dataset management is understanding the dynamic lifestyle habits and implications to personal well-being. The exploitation of the dataset fosters an overview regarding the causative agents to physicians’ demand for more health-based details. Primarily, it is safe to use Hadoop to manage big data since it enlightens the stakeholders concerning specific issues within a single spectrum, such as healthcare quality.\n",
      "\n",
      "Hadoop as A Recommended Big Data Analytics Technology\n",
      "\n",
      "I would recommend using Hadoop to manage big data due to the importance of enhancing productivity. Efficiency in utilizing massive datasets empowers corporates with insights regarding distinctive approaches to consumer behavioral patterns. Apart from the necessity of understanding the clientele, other institutions sufficiently comprehend the changes in a particular system. An excellent example is the gathering weather changes and sequence as a formative strategy to demonstrate the unprecedented climate change. In this case, it is key stakeholders’ responsibility to uphold the relevance of Hadoop due to the intersection of dynamic details. Hadoop technology significantly contributes to the execution and implementation of action plans objectively (Data Flair, 2022). Over the decades, the intensification in technological use rendered the increase in the scoop of big data daily. As a result, data analytics corporates seek approaches, such as using Hadoop to enhance the productivity scale on adjusting to the evolutionary cycle. Therefore, Hadoop is recommended to boost the performance rationale across different professional practices and sectors.\n",
      "\n",
      "Hadoop Code and The Significance\n",
      "\n",
      "There are different coding mechanisms within the Hadoop system for optimal outcomes. The two standard codes include mapper and reducer, which mainly enhance datasets’ compilation under the spectrum of divide and conquer. Therefore, programmers exploit the coded language to analyze distinctive massive datasets for specific information. Below is a description of the mapper and reducer codes and their significance to the processing.\n",
      "\n",
      "Mapper code\n",
      "\n",
      "1  publicstaticclassMap extendsMapper{                              \n",
      "2  publicvoidmap(LongWritable key, Text value, Context context) throwsIOException,InterruptedException {\n",
      "3  String line = value.toString();                                                                      \n",
      "4  StringTokenizer tokenizer = newStringTokenizer(line);                                                \n",
      "5  while(tokenizer.hasMoreTokens()) {                                                                   \n",
      "6  value.set(tokenizer.nextToken());                                                                    \n",
      "7  context.write(value, newIntWritable(1));                                                             \n",
      "8  }                                                                                                    \n",
      "\n",
      "\n",
      "The code represents the class-map used to extend the mapper defined in the MapReduce framework. In this case, the program significantly utilizes the coding to establish inherent values on input and output keys after the declaration by using the angle brackets. In this case, a java code is used in tokenizing every word and assigning a hardcoded key equivalent to 1.\n",
      "\n",
      "Reducer Code\n",
      "\n",
      "1   publicstaticclassReduce extendsReducer{\n",
      "2   publicvoidreduce(Text key, Iterablevalues,Context context)                \n",
      "3   throwsIOException,InterruptedException {                                  \n",
      "4   intsum=0;                                                                 \n",
      "5   for(IntWritable x: values)                                                \n",
      "6   {                                                                         \n",
      "7   sum+=x.get();                                                             \n",
      "8   }                                                                         \n",
      "9   context.write(key, newIntWritable(sum));                                  \n",
      "10  }                                                                         \n",
      "11  }                                                                         \n",
      "\n",
      "\n",
      "The above is a reducer class code that enshrines the apt use of extension in the ClassReducer. The input and output keys significantly attributed to the key-value pair and the necessity of boosting the performance scale. It is vital to establish the distinctive role of a single reducer using unique words to get a final answer. The Hadoop coding operates under the divide and rule perspective. In this case, the programmer focuses on the intersection of mapper and reducer to enhance the analysis of a weather update and the prediction of changes in the future. Therefore, the coded approach is an essential attributable baseline for corporates in improving the optimal gathering and analysis of big data.\n",
      "\n",
      "Hadoop Interface Tools and Their Roles\n",
      "\n",
      "The two primary Hadoop tools encompass HDFS and YARN, which play a crucial role in the performance scale of the system. HDFS focuses on the storage of big data and the ease of accessibility. In this case, Hadoop ensures the apt function of the storage units for the information gathered and prepared for assessment. YARN is another tool used for processing the collected big data (Data Flair, 2022). The element utilizes different codes in the management and analyses of the dataset to derive crucial insights. The lack of clarity risks miscommunication and inefficient execution of action plans. Therefore, it is the responsibility of programmers to establish core values on intersecting the YARN and HDFS values for adept productivity across the various institutions. The coordination of storage and processing units fosters intensifying the derivation of crucial details. As a result, it is essential to ensure optimal professionalism in the coding structure.\n",
      "\n",
      "The List of Companies using Hadoop Technology\n",
      "\n",
      "  * Marks and Spencer\n",
      "  * Royal Mail\n",
      "  * British Airways\n",
      "  * Royal Bank of Scotland\n",
      "  * Expedia\n",
      "  * Amazon Web Services\n",
      "  * ScienceSoft\n",
      "  * Pivotal\n",
      "  * IBM\n",
      "  * Microsoft\n",
      "  * Hortonworks\n",
      "  * MapR\n",
      "  * Datameer\n",
      "  * Adello\n",
      "  * Hadapt\n",
      "  * Kamasphere\n",
      "  * NG Data\n",
      "\n",
      "References\n",
      "\n",
      "Data Flair. (2022). 12 frequently used Hadoop HDFS Commands with Examples & usage. Web.\n",
      "\n",
      "Rowe, W. (2016). Hadoop Tutorial for Beginners: Hadoop Basics. [online] BMC Blogs. Web.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(df_AI_pcs[\"output\"][23])\n",
    "print(df_human_pcs[\"TEXT\"][373])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a king she is a queen\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "example=\"I am a #king, she is a #queen.\"\n",
    "print(remove_punct(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         The review is neutral. The reviewer did not ha...\n",
       "1         Okay, let's solve this math problem together! ...\n",
       "2         As an AI, I understand you are asking for a tw...\n",
       "3         The sentence is acceptable. It means that the ...\n",
       "4         The article does not provide the last name of ...\n",
       "                                ...                        \n",
       "233167    We can convert $\\frac{5}{14}$ into a decimal b...\n",
       "233168    First, we find the prime factorization of each...\n",
       "233169    The students are advised to eat normal-sized m...\n",
       "233170    Jean thought \"David\" was special because he ma...\n",
       "233171                                            homology.\n",
       "Name: output, Length: 233172, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_pcs[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_pcs[\"output\"] = df_AI_pcs[\"output\"].apply(lambda x : remove_punct(x))\n",
    "df_human_pcs[\"TEXT\"] = df_human_pcs[\"TEXT\"].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         The review is neutral The reviewer did not hav...\n",
       "1         Okay lets solve this math problem together \\n\\...\n",
       "2         As an AI I understand you are asking for a twe...\n",
       "3         The sentence is acceptable It means that the s...\n",
       "4         The article does not provide the last name of ...\n",
       "                                ...                        \n",
       "233167    We can convert frac514 into a decimal by long ...\n",
       "233168    First we find the prime factorization of each ...\n",
       "233169    The students are advised to eat normalsized me...\n",
       "233170    Jean thought David was special because he made...\n",
       "233171                                             homology\n",
       "Name: output, Length: 233172, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_pcs[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df_AI_pcs 233172\n",
      "length of df_human_pcs 128293\n"
     ]
    }
   ],
   "source": [
    "print(\"length of df_AI_pcs:\", len(df_AI_pcs.index))\n",
    "print(\"length of df_human_pcs:\", len(df_human_pcs.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_clean = df_AI_pcs.iloc[:len(df_human_pcs.index),:]\n",
    "df_human_clean = df_human_pcs.iloc[:len(df_human_pcs.index),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/rlbty0wj62qgtp38sml170rr0000gn/T/ipykernel_26295/2772657309.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_AI_clean[\"label\"] = 1\n",
      "/var/folders/25/rlbty0wj62qgtp38sml170rr0000gn/T/ipykernel_26295/2772657309.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_human_clean[\"label\"] = 0\n"
     ]
    }
   ],
   "source": [
    "df_AI_clean[\"label\"] = 1\n",
    "df_human_clean[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Years a Slave An Analysis of the Film Essay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20 Social Media Post Ideas to Radically Simpli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533 US 27 2001 Kyllo v United States The Use o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  label\n",
       "0  12 Years a Slave An Analysis of the Film Essay...      0\n",
       "1  20 Social Media Post Ideas to Radically Simpli...      0\n",
       "2  2022 Russian Invasion of Ukraine in Global Med...      0\n",
       "3  533 US 27 2001 Kyllo v United States The Use o...      0\n",
       "4  A Charles Schwab Corporation Case Essay\\n\\nCha...      0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AI_clean.head()\n",
    "df_human_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_AI_clean.to_csv(\"../Clean_data/ai_gen_text_v2.csv\", index = False)\n",
    "# df_human_clean.to_csv(\"../Clean_data/human_wrttn_text_v2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling Checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spellchecker import SpellChecker\n",
    "\n",
    "# spell = SpellChecker()\n",
    "# def correct_spellings(text):\n",
    "#     corrected_text = []\n",
    "#     misspelled_words = spell.unknown(text.split())\n",
    "#     for word in text.split():\n",
    "#         if word in misspelled_words:\n",
    "#             corrected_text.append(spell.correction(word))\n",
    "#         else:\n",
    "#             corrected_text.append(word)\n",
    "#     return \" \".join(corrected_text)\n",
    "        \n",
    "# text = \"corect me plese\"\n",
    "# correct_spellings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text']=df['text'].apply(lambda x : correct_spellings(x)#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
